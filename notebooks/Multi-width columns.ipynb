{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9ec8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5059d0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uuid_field', 'int_field5']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parser(\"SELECT uuid_field, int_field5 FROM jungle WHERE int_field5 >= 95487 AND int_field5 < 96074\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac13458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sql_metadata import Parser\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import psycopg2 as pg\n",
    "from pglast import parser\n",
    "from random import shuffle\n",
    "\n",
    "CONNECTION_STRING = \"dbname='project1db' user='project1user' password='project1pass' host='localhost'\"\n",
    "\n",
    "def get_table_column_map(conn):\n",
    "    QUERY = \"select table_name, column_name from information_schema.columns where table_schema='public';\"\n",
    "    \n",
    "    table_columns_map = defaultdict(set)\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(QUERY)\n",
    "        db_columns = cursor.fetchall()\n",
    "        for table, column in db_columns:\n",
    "            table_columns_map[table].add(column)\n",
    "    return table_columns_map\n",
    "        \n",
    "\n",
    "\n",
    "def filter_interesting_queries(queries):\n",
    "    res = [re.sub(r'^statement: ', '', q)\n",
    "           for q in queries if q.startswith('statement')]\n",
    "    res = [q for q in res if 'pg_' not in q and not q.startswith('SHOW ALL') and not q.startswith(\n",
    "        'COMMIT') and not q.startswith('SET') and not q.startswith('BEGIN')]\n",
    "    res = [q for q in res if 'WHERE' in q or 'ORDER' in q or 'JOIN' in q or 'join' in q or 'where' in q or 'order' in q]\n",
    "    return res\n",
    "\n",
    "\n",
    "def cluster_queries(queries):\n",
    "    group_counts = defaultdict(int)\n",
    "    group_repr = {}\n",
    "    gqueries = set()\n",
    "    for query in queries:\n",
    "        try:\n",
    "            generalized = parser.fingerprint(query)\n",
    "            group_counts[generalized] += 1\n",
    "            group_repr[generalized] = query\n",
    "            gqueries.add(generalized)\n",
    "        except:\n",
    "            pass\n",
    "    return gqueries, group_counts, group_repr\n",
    "\n",
    "\n",
    "def get_relevant_columns(clusters, cluster_counts, table_column_map):\n",
    "    column_usage_counts = defaultdict(int)\n",
    "    tables = []\n",
    "    table_columns = defaultdict(set)\n",
    "\n",
    "    for qgroup, query in clusters.items():\n",
    "        try:\n",
    "            pq = Parser(query)\n",
    "            tables.extend(pq.tables)\n",
    "            columns = pq.columns_dict\n",
    "            pq_tables = pq.tables\n",
    "            groups = ['where', 'order_by', 'join']\n",
    "            for group in groups:\n",
    "                if group in columns:\n",
    "                    standardised_columns = []\n",
    "                    for col in columns[group]:\n",
    "                        if '.' not in col:\n",
    "                            for table in pq_tables:\n",
    "                                if table in table_column_map and col in table_column_map[table]:\n",
    "                                    col = table + '.' + col\n",
    "                                    break\n",
    "                        column_usage_counts[col] += cluster_counts[qgroup]\n",
    "                        tab, c = col.split('.')\n",
    "                        table_columns[tab].add(col)\n",
    "        except:\n",
    "            pass\n",
    "    tables = set(tables)\n",
    "    ordered_columns = list(\n",
    "        reversed(sorted(list(column_usage_counts.items()), key=lambda x: x[1])))\n",
    "    return ordered_columns, table_columns\n",
    "\n",
    "\n",
    "def get_combinations_list(table_columns, max_index_width):\n",
    "    combs = []\n",
    "    # all_column_combinations = [_ for _ in ordered_columns]\n",
    "    \n",
    "    all_columns_combinations = []\n",
    "    for table, cols in table_columns.items():\n",
    "        tcols = list(cols)\n",
    "        for width in range(1, max_index_width+1):\n",
    "            all_columns_combinations.extend(combinations(tcols, width))\n",
    "    for i in range(1, len(all_columns_combinations)+1):\n",
    "        combs.extend(combinations(all_columns_combinations, i))\n",
    "\n",
    "    shuffle(combs)\n",
    "    return combs\n",
    "\n",
    "\n",
    "def get_columns_from_logs(logs_path):\n",
    "    QCOL = 13\n",
    "    df = pd.read_csv(logs_path, header=None)\n",
    "    queries = filter_interesting_queries(df[QCOL].tolist())\n",
    "    with pg.connect(CONNECTION_STRING) as conn:\n",
    "        table_column_map = get_table_column_map(conn)\n",
    "        print(table_column_map)\n",
    "    gqueries, group_counts, group_repr = cluster_queries(queries)\n",
    "    cols, table_columns = get_relevant_columns(group_repr, group_counts, table_column_map)\n",
    "    return cols, table_columns, group_counts, group_repr\n",
    "\n",
    "\n",
    "def generate_index_creation_queries(columns):\n",
    "    query_template = 'CREATE INDEX ON {} ({})'\n",
    "    queries = []\n",
    "    \n",
    "    for column_group in columns:\n",
    "        \n",
    "        table_name = column_group[0].split('.')[0]\n",
    "        \n",
    "        columns = [column.split('.')[1] for column in column_group]   \n",
    "        \n",
    "        queries.append(query_template.format(table_name, ', '.join(columns)))\n",
    "        \n",
    "    return queries\n",
    "\n",
    "\n",
    "def create_hypothetical_indexes(index_queries, conn):\n",
    "    hypo_template = \"SELECT * FROM hypopg_create_index('{}');\"\n",
    "    with conn.cursor() as cur:\n",
    "        for index_creation_query in index_queries:\n",
    "            cur.execute(hypo_template.format(index_creation_query))\n",
    "            res = cur.fetchall()\n",
    "\n",
    "\n",
    "def get_scaled_loss(group_counts, costs):\n",
    "    cost = 0.\n",
    "    for cluster, count in group_counts.items():\n",
    "        cost += count*costs[cluster]\n",
    "    return cost\n",
    "\n",
    "\n",
    "def remove_hypo_indexes(conn):\n",
    "    reset_indexes_q = 'SELECT * FROM hypopg_reset();'\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(reset_indexes_q)\n",
    "        res = cur.fetchall()\n",
    "\n",
    "\n",
    "def enable_hypopg(conn):\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute('CREATE EXTENSION IF NOT EXISTS hypopg;')\n",
    "\n",
    "\n",
    "def get_query_costs(query_clusters, conn):\n",
    "    costs = dict()\n",
    "    with conn.cursor() as cur:\n",
    "        for cluster, query in query_clusters.items():\n",
    "            cur.execute('EXPLAIN (FORMAT JSON) '+query)\n",
    "            explain_res = cur.fetchall()\n",
    "            costs[cluster] = explain_res[0][0][0]['Plan']['Total Cost']\n",
    "    return costs\n",
    "\n",
    "\n",
    "def find_best_index(log_file_path):\n",
    "    cols, table_columns, group_counts, group_repr = get_columns_from_logs(\n",
    "        log_file_path)\n",
    "    cmbns = get_combinations_list(cols, table_columns)\n",
    "    best_config = []\n",
    "    with pg.connect(\"dbname='project1db' user='project1user' password='project1pass' host='localhost'\") as conn:\n",
    "        baseline_costs = get_query_costs(group_repr, conn)\n",
    "        baseline_cost = get_scaled_loss(group_counts, baseline_costs)\n",
    "        baseline_cost\n",
    "        min_cost = baseline_cost\n",
    "        best_config = []\n",
    "        enable_hypopg(conn)\n",
    "        for cmb in cmbns:\n",
    "            index_q = generate_index_creation_queries(cmb)\n",
    "            create_hypothetical_indexes(index_q, conn)\n",
    "            costs = get_query_costs(group_repr, conn)\n",
    "            cost = get_scaled_loss(group_counts, costs)\n",
    "            remove_hypo_indexes(conn)\n",
    "            print(cmb, cost)\n",
    "            if cost < min_cost or (cost == min_cost and len(cmb) < len(best_config)):\n",
    "                min_cost = cost\n",
    "                best_config = cmb\n",
    "\n",
    "    index_creation_queries = generate_index_creation_queries(best_config)\n",
    "    with open('actions.sql', 'w') as f:\n",
    "        for query in index_creation_queries:\n",
    "            \n",
    "            f.write(\"{};\\n\".format(query))\n",
    "    with open('config.json', 'w') as f:\n",
    "        f.write('{\"VACUUM\": false}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca157993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25293/1491388032.py:98: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(logs_path, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'jungle': {'varchar_field8', 'timestamp_field3', 'int_field9', 'timestamp_field8', 'timestamp_field1', 'int_field0', 'int_field1', 'timestamp_field0', 'varchar_field5', 'int_field5', 'varchar_field2', 'varchar_field4', 'float_field7', 'float_field8', 'int_field4', 'int_field7', 'float_field2', 'timestamp_field7', 'varchar_field0', 'timestamp_field5', 'float_field1', 'varchar_field7', 'int_field6', 'int_field2', 'timestamp_field4', 'int_field3', 'varchar_field1', 'varchar_field6', 'float_field9', 'float_field3', 'varchar_field9', 'float_field0', 'timestamp_field6', 'timestamp_field9', 'float_field4', 'timestamp_field2', 'uuid_field', 'int_field8', 'varchar_field3', 'float_field5', 'float_field6'}, 'hypopg_list_indexes': {'am_name', 'table_name', 'index_name', 'indexrelid', 'schema_name'}})\n"
     ]
    }
   ],
   "source": [
    "# log_file_path = 'epinions.csv'\n",
    "log_file_path = 'indexjungle.csv'\n",
    "\n",
    "cols, table_columns, group_counts, group_repr = get_columns_from_logs(\n",
    "        log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0e31642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'jungle': {'jungle.float_field0',\n",
       "              'jungle.float_field1',\n",
       "              'jungle.float_field2',\n",
       "              'jungle.float_field3',\n",
       "              'jungle.float_field4',\n",
       "              'jungle.float_field5',\n",
       "              'jungle.float_field6',\n",
       "              'jungle.float_field7',\n",
       "              'jungle.float_field8',\n",
       "              'jungle.float_field9',\n",
       "              'jungle.int_field1',\n",
       "              'jungle.int_field5',\n",
       "              'jungle.int_field7',\n",
       "              'jungle.uuid_field'}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(table_columns['jungle']))\n",
    "table_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ff49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WIDTH = 1\n",
    "cmbns = get_combinations_list(table_columns, MAX_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b161282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16383"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cmbns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05d42066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('jungle.int_field5',),\n",
       "  ('jungle.float_field6',),\n",
       "  ('jungle.float_field4',),\n",
       "  ('jungle.float_field9',),\n",
       "  ('jungle.float_field5',),\n",
       "  ('jungle.int_field1',)),\n",
       " (('jungle.float_field8',),\n",
       "  ('jungle.float_field6',),\n",
       "  ('jungle.float_field4',),\n",
       "  ('jungle.float_field7',),\n",
       "  ('jungle.uuid_field',),\n",
       "  ('jungle.float_field1',),\n",
       "  ('jungle.float_field5',)),\n",
       " (('jungle.float_field8',),\n",
       "  ('jungle.int_field5',),\n",
       "  ('jungle.float_field4',),\n",
       "  ('jungle.float_field9',),\n",
       "  ('jungle.uuid_field',),\n",
       "  ('jungle.float_field0',)),\n",
       " (('jungle.float_field8',),\n",
       "  ('jungle.int_field5',),\n",
       "  ('jungle.float_field4',),\n",
       "  ('jungle.float_field7',),\n",
       "  ('jungle.float_field9',),\n",
       "  ('jungle.float_field1',),\n",
       "  ('jungle.float_field3',),\n",
       "  ('jungle.float_field5',),\n",
       "  ('jungle.float_field0',)),\n",
       " (('jungle.float_field8',),\n",
       "  ('jungle.int_field5',),\n",
       "  ('jungle.float_field2',),\n",
       "  ('jungle.uuid_field',),\n",
       "  ('jungle.float_field1',),\n",
       "  ('jungle.float_field3',),\n",
       "  ('jungle.float_field5',),\n",
       "  ('jungle.float_field0',)),\n",
       " (('jungle.float_field6',),\n",
       "  ('jungle.float_field7',),\n",
       "  ('jungle.int_field7',),\n",
       "  ('jungle.float_field9',),\n",
       "  ('jungle.uuid_field',),\n",
       "  ('jungle.float_field1',),\n",
       "  ('jungle.float_field3',)),\n",
       " (('jungle.float_field8',),\n",
       "  ('jungle.int_field5',),\n",
       "  ('jungle.float_field2',),\n",
       "  ('jungle.float_field6',),\n",
       "  ('jungle.float_field4',),\n",
       "  ('jungle.int_field7',),\n",
       "  ('jungle.float_field9',),\n",
       "  ('jungle.float_field1',),\n",
       "  ('jungle.float_field3',),\n",
       "  ('jungle.int_field1',)),\n",
       " (('jungle.float_field8',),\n",
       "  ('jungle.int_field5',),\n",
       "  ('jungle.uuid_field',),\n",
       "  ('jungle.float_field1',),\n",
       "  ('jungle.float_field0',),\n",
       "  ('jungle.int_field1',)),\n",
       " (('jungle.float_field8',),\n",
       "  ('jungle.float_field2',),\n",
       "  ('jungle.float_field6',),\n",
       "  ('jungle.int_field7',),\n",
       "  ('jungle.uuid_field',),\n",
       "  ('jungle.float_field0',)),\n",
       " (('jungle.float_field8',),\n",
       "  ('jungle.int_field5',),\n",
       "  ('jungle.float_field7',),\n",
       "  ('jungle.int_field7',),\n",
       "  ('jungle.uuid_field',),\n",
       "  ('jungle.float_field1',),\n",
       "  ('jungle.float_field3',),\n",
       "  ('jungle.float_field5',))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmbns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a0ae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CREATE INDEX ON jungle (float_field8)',\n",
       " 'CREATE INDEX ON jungle (int_field5)',\n",
       " 'CREATE INDEX ON jungle (float_field6)',\n",
       " 'CREATE INDEX ON jungle (float_field7)',\n",
       " 'CREATE INDEX ON jungle (uuid_field)',\n",
       " 'CREATE INDEX ON jungle (float_field1)',\n",
       " 'CREATE INDEX ON jungle (float_field3)',\n",
       " 'CREATE INDEX ON jungle (int_field1)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_index_creation_queries(cmbns[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b73d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = []\n",
    "with open('config.json', 'w') as f:\n",
    "    f.write('{\"VACUUM\": false}')\n",
    "with pg.connect(CONNECTION_STRING) as conn:\n",
    "    baseline_costs = get_query_costs(group_repr, conn)\n",
    "    baseline_cost = get_scaled_loss(group_counts, baseline_costs)\n",
    "    min_cost = baseline_cost\n",
    "    best_config = []\n",
    "    enable_hypopg(conn)\n",
    "    for i, cmb in enumerate(cmbns):\n",
    "        index_q = generate_index_creation_queries(cmb)\n",
    "        create_hypothetical_indexes(index_q, conn)\n",
    "        costs = get_query_costs(group_repr, conn)\n",
    "        cost = get_scaled_loss(group_counts, costs)\n",
    "        remove_hypo_indexes(conn)\n",
    "#         print(cmb, cost)\n",
    "        if cost < min_cost or (cost == min_cost and len(cmb) < len(best_config)):\n",
    "            min_cost = cost\n",
    "            best_config = cmb\n",
    "        if i%1000 == 0:\n",
    "            with open('actions.sql', 'w') as f:\n",
    "                for query in index_q:\n",
    "                    f.write(\"{};\\n\".format(query))\n",
    "\n",
    "index_creation_queries = generate_index_creation_queries(best_config)\n",
    "with open('actions.sql', 'w') as f:\n",
    "    for query in index_creation_queries:\n",
    "\n",
    "        f.write(\"{};\\n\".format(query))\n",
    "\n",
    "# print('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33659c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CREATE INDEX ON jungle (int_field5)',\n",
       " 'CREATE INDEX ON jungle (int_field7)',\n",
       " 'CREATE INDEX ON jungle (uuid_field)',\n",
       " 'CREATE INDEX ON jungle (int_field1)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_creation_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2493ad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940959.0200000004"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# width 3\n",
    "min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae50deed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484797.90999999957"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# width 1\n",
    "min_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe6a95d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CREATE INDEX ON item (i_id)',\n",
       " 'CREATE INDEX ON review (i_id, u_id)',\n",
       " 'CREATE INDEX ON review (u_id, creation_date)',\n",
       " 'CREATE INDEX ON useracct (u_id)',\n",
       " 'CREATE INDEX ON trust (source_u_id)',\n",
       " 'CREATE INDEX ON trust (target_u_id, source_u_id)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_creation_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e5909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(940959.0200000004, 15786295.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# width 2\n",
    "min_cost, baseline_cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
